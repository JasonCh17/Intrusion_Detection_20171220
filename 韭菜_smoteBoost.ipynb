{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "import time\n",
    "import pandas as pd #数据分析\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#混淆矩阵\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    # plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "time_start=time.time()\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
    "data= pd.read_csv(\"E:\\Pycharm\\Intrusion_Detection\\kddcup.data_10_percent.csv\",  header=None,names = col_names)\n",
    "\n",
    "#去重\n",
    "# import matplotlib.pyplot as plt\n",
    "# IsDuplicated=data.duplicated()\n",
    "#\n",
    "# IsDuplicated.value_counts().plot(kind='bar')\n",
    "# plt.show()\n",
    "data_1=data.drop_duplicates()\n",
    "\n",
    "#one-hot\n",
    "dummies_protocol = pd.get_dummies(data_1[\"protocol_type\"], prefix='protocol')\n",
    "dummies_flag = pd.get_dummies(data_1[\"flag\"], prefix='flag')\n",
    "# dummies_service = pd.get_dummies(data_1[\"service\"], prefix='service')\n",
    "# data_2 = pd.concat([data_1, dummies_protocol,dummies_flag,dummies_service], axis=1)\n",
    "data_2 = pd.concat([data_1, dummies_protocol,dummies_flag], axis=1)\n",
    "# data_2\n",
    "#特征选择(by \"A feature reduced intrusion detection system using ANN classifier\",25个特征）\n",
    "#建立X,y\n",
    "feature_selection=[\"duration\",\n",
    "    \"dst_bytes\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_access_files\",\n",
    "    \"num_outbound_cmds\",\"is_guest_login\",\"rerror_rate\",\"srv_diff_host_rate\",\n",
    "    \"dst_host_count\",\"dst_host_srv_count\",\"dst_host_same_srv_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n",
    "    \"protocol_icmp\",\"protocol_tcp\",\"protocol_udp\",\n",
    "    \"flag_OTH\",\"flag_REJ\",\"flag_RSTO\",\"flag_RSTOS0\",\"flag_RSTR\",\n",
    "    \"flag_S0\",\"flag_S1\",\"flag_S2\",\"flag_S3\",\"flag_SF\",\"flag_SH\"]\n",
    "X_3=data_2[feature_selection]\n",
    "y_3=data_2['label'].copy()   #一维\n",
    "##y的处理\n",
    "u2r=[\"buffer_overflow.\",\"loadmodule.\",\"perl.\",\"rootkit.\"]\n",
    "r2l=[\"ftp_write.\",\"imap.\",\"guess_passwd.\",\"phf.\",\"spy.\",\"multihop.\",\"warezmaster.\",\"warezclient.\"]\n",
    "dos=[\"back.\",\"land.\",\"pod.\",\"neptune.\",\"smurf.\",\"teardrop.\"]\n",
    "probe=[\"satan.\",\"portsweep.\",\"ipsweep.\",\"nmap.\"]\n",
    "for i in u2r:\n",
    "    y_3[y_3==i]='1' #u2r\n",
    "for i in r2l:\n",
    "    y_3[y_3==i]='1' #r2l\n",
    "for i in dos:\n",
    "    y_3[y_3==i]='1'  #dos\n",
    "    \n",
    "for i in probe:\n",
    "    y_3[y_3==i]='1' #probe\n",
    "y_3[y_3==\"normal.\"]='0' #normal\n",
    "y_3=np.array(y_3)  #变成array格式，一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import is_regressor\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble.forest import BaseForest\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.tree.tree import BaseDecisionTree\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "#from sklearn.utils import shuffle\n",
    "from sklearn.utils import check_X_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SMOTE(object):\n",
    "\n",
    "    \"\"\"Implementation of Synthetic Minority Over-Sampling Technique (SMOTE).\n",
    "\n",
    "\n",
    "\n",
    "    SMOTE performs oversampling of the minority class by picking target \n",
    "\n",
    "    minority class samples and their nearest minority class neighbors and \n",
    "\n",
    "    generating new samples that linearly combine features of each target \n",
    "\n",
    "    sample with features of its selected minority class neighbors [1].\n",
    "\n",
    "\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "\n",
    "    k_neighbors : int, optional (default=5)\n",
    "\n",
    "        Number of nearest neighbors.\n",
    "\n",
    "    random_state : int or None, optional (default=None)\n",
    "\n",
    "        If int, random_state is the seed used by the random number generator.\n",
    "\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "\n",
    "        by np.random.\n",
    "\n",
    "\n",
    "\n",
    "    References\n",
    "\n",
    "    ----------\n",
    "\n",
    "    .. [1] N. V. Chawla, K. W. Bowyer, L. O. Hall, and P. Kegelmeyer. \"SMOTE:\n",
    "\n",
    "           Synthetic Minority Over-Sampling Technique.\" Journal of Artificial\n",
    "\n",
    "           Intelligence Research (JAIR), 2002.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, k_neighbors=5, random_state=None):\n",
    "\n",
    "        self.k = k_neighbors\n",
    "\n",
    "        self.random_state = random_state\n",
    "\n",
    "\n",
    "\n",
    "    def sample(self, n_samples):\n",
    "\n",
    "        \"\"\"Generate samples.\n",
    "\n",
    "\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "        n_samples : int\n",
    "\n",
    "            Number of new synthetic samples.\n",
    "\n",
    "\n",
    "\n",
    "        Returns\n",
    "\n",
    "        -------\n",
    "\n",
    "        S : array, shape = [n_samples, n_features]\n",
    "\n",
    "            Returns synthetic samples.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(seed=self.random_state)\n",
    "\n",
    "\n",
    "\n",
    "        S = np.zeros(shape=(n_samples, self.n_features))\n",
    "\n",
    "        # Calculate synthetic samples.\n",
    "\n",
    "        for i in range(n_samples):\n",
    "\n",
    "            j = np.random.randint(0, self.X.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "            # Find the NN for each sample.\n",
    "\n",
    "            # Exclude the sample itself.\n",
    "\n",
    "            nn = self.neigh.kneighbors(self.X[j].reshape(1, -1),\n",
    "\n",
    "                                       return_distance=False)[:, 1:]\n",
    "\n",
    "            nn_index = np.random.choice(nn[0])\n",
    "\n",
    "\n",
    "\n",
    "            dif = self.X[nn_index] - self.X[j]\n",
    "\n",
    "            gap = np.random.random()\n",
    "\n",
    "\n",
    "\n",
    "            S[i, :] = self.X[j, :] + gap * dif[:]\n",
    "\n",
    "\n",
    "\n",
    "        return S\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "\n",
    "        \"\"\"Train model based on input data.\n",
    "\n",
    "\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "        X : array-like, shape = [n_minority_samples, n_features]\n",
    "\n",
    "            Holds the minority samples.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        self.n_minority_samples, self.n_features = self.X.shape\n",
    "\n",
    "\n",
    "\n",
    "        # Learn nearest neighbors.\n",
    "\n",
    "        self.neigh = NearestNeighbors(n_neighbors=self.k + 1)\n",
    "\n",
    "        self.neigh.fit(self.X)\n",
    "\n",
    "\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SMOTEBoost(AdaBoostClassifier):\n",
    "\n",
    "    \"\"\"Implementation of SMOTEBoost.\n",
    "\n",
    "\n",
    "\n",
    "    SMOTEBoost introduces data sampling into the AdaBoost algorithm by\n",
    "\n",
    "    oversampling the minority class using SMOTE on each boosting iteration [1].\n",
    "\n",
    "\n",
    "\n",
    "    This implementation inherits methods from the scikit-learn \n",
    "\n",
    "    AdaBoostClassifier class, only modifying the `fit` method.\n",
    "\n",
    "\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "\n",
    "    n_samples : int, optional (default=100)\n",
    "\n",
    "        Number of new synthetic samples per boosting step.\n",
    "\n",
    "    k_neighbors : int, optional (default=5)\n",
    "\n",
    "        Number of nearest neighbors.\n",
    "\n",
    "    base_estimator : object, optional (default=DecisionTreeClassifier)\n",
    "\n",
    "        The base estimator from which the boosted ensemble is built.\n",
    "\n",
    "        Support for sample weighting is required, as well as proper `classes_`\n",
    "\n",
    "        and `n_classes_` attributes.\n",
    "\n",
    "    n_estimators : int, optional (default=50)\n",
    "\n",
    "        The maximum number of estimators at which boosting is terminated.\n",
    "\n",
    "        In case of perfect fit, the learning procedure is stopped early.\n",
    "\n",
    "    learning_rate : float, optional (default=1.)\n",
    "\n",
    "        Learning rate shrinks the contribution of each classifier by\n",
    "\n",
    "        ``learning_rate``. There is a trade-off between ``learning_rate`` and\n",
    "\n",
    "        ``n_estimators``.\n",
    "\n",
    "    algorithm : {'SAMME', 'SAMME.R'}, optional (default='SAMME.R')\n",
    "\n",
    "        If 'SAMME.R' then use the SAMME.R real boosting algorithm.\n",
    "\n",
    "        ``base_estimator`` must support calculation of class probabilities.\n",
    "\n",
    "        If 'SAMME' then use the SAMME discrete boosting algorithm.\n",
    "\n",
    "        The SAMME.R algorithm typically converges faster than SAMME,\n",
    "\n",
    "        achieving a lower test error with fewer boosting iterations.\n",
    "\n",
    "    random_state : int or None, optional (default=None)\n",
    "\n",
    "        If int, random_state is the seed used by the random number generator.\n",
    "\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "\n",
    "        by np.random.\n",
    "\n",
    "\n",
    "\n",
    "    References\n",
    "\n",
    "    ----------\n",
    "\n",
    "    .. [1] N. V. Chawla, A. Lazarevic, L. O. Hall, and K. W. Bowyer.\n",
    "\n",
    "           \"SMOTEBoost: Improving Prediction of the Minority Class in\n",
    "\n",
    "           Boosting.\" European Conference on Principles of Data Mining and\n",
    "\n",
    "           Knowledge Discovery (PKDD), 2003.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "\n",
    "                 n_samples=100,\n",
    "\n",
    "                 k_neighbors=5,\n",
    "\n",
    "                 base_estimator=None,\n",
    "\n",
    "                 n_estimators=50,\n",
    "\n",
    "                 learning_rate=1.,\n",
    "\n",
    "                 algorithm='SAMME.R',\n",
    "\n",
    "                 random_state=None):\n",
    "\n",
    "\n",
    "\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "        self.smote = SMOTE(k_neighbors=k_neighbors,\n",
    "\n",
    "                           random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "        super(SMOTEBoost, self).__init__(\n",
    "\n",
    "            base_estimator=base_estimator,\n",
    "\n",
    "            n_estimators=n_estimators,\n",
    "\n",
    "            learning_rate=learning_rate,\n",
    "\n",
    "            random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, minority_target=None):\n",
    "\n",
    "        \"\"\"Build a boosted classifier/regressor from the training set (X, y),\n",
    "\n",
    "        performing SMOTE during each boosting step.\n",
    "\n",
    "\n",
    "\n",
    "        Parameters\n",
    "\n",
    "        ----------\n",
    "\n",
    "        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
    "\n",
    "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
    "\n",
    "            DOK, or LIL. COO, DOK, and LIL are converted to CSR. The dtype is\n",
    "\n",
    "            forced to DTYPE from tree._tree if the base classifier of this\n",
    "\n",
    "            ensemble weighted boosting classifier is a tree or forest.\n",
    "\n",
    "        y : array-like of shape = [n_samples]\n",
    "\n",
    "            The target values (class labels in classification, real numbers in\n",
    "\n",
    "            regression).\n",
    "\n",
    "        sample_weight : array-like of shape = [n_samples], optional\n",
    "\n",
    "            Sample weights. If None, the sample weights are initialized to\n",
    "\n",
    "            1 / n_samples.\n",
    "\n",
    "        minority_target : int\n",
    "\n",
    "            Minority class label.\n",
    "\n",
    "\n",
    "\n",
    "        Returns\n",
    "\n",
    "        -------\n",
    "\n",
    "        self : object\n",
    "\n",
    "            Returns self.\n",
    "\n",
    "\n",
    "\n",
    "        Notes\n",
    "\n",
    "        -----\n",
    "\n",
    "        Based on the scikit-learn v0.18 AdaBoostClassifier and\n",
    "\n",
    "        BaseWeightBoosting `fit` methods.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that algorithm is supported.\n",
    "\n",
    "        if self.algorithm not in ('SAMME', 'SAMME.R'):\n",
    "\n",
    "            raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n",
    "\n",
    "\n",
    "\n",
    "        # Check parameters.\n",
    "\n",
    "        if self.learning_rate <= 0:\n",
    "\n",
    "            raise ValueError(\"learning_rate must be greater than zero\")\n",
    "\n",
    "\n",
    "\n",
    "        if (self.base_estimator is None or\n",
    "\n",
    "                isinstance(self.base_estimator, (BaseDecisionTree,\n",
    "\n",
    "                                                 BaseForest))):\n",
    "\n",
    "            DTYPE = np.float64  # from fast_dict.pxd\n",
    "\n",
    "            dtype = DTYPE\n",
    "\n",
    "            accept_sparse = 'csc'\n",
    "\n",
    "        else:\n",
    "\n",
    "            dtype = None\n",
    "\n",
    "            accept_sparse = ['csr', 'csc']\n",
    "\n",
    "\n",
    "\n",
    "        X, y = check_X_y(X, y, accept_sparse=accept_sparse, dtype=dtype,\n",
    "\n",
    "                         y_numeric=is_regressor(self))\n",
    "\n",
    "\n",
    "\n",
    "        if sample_weight is None:\n",
    "\n",
    "            # Initialize weights to 1 / n_samples.\n",
    "\n",
    "            sample_weight = np.empty(X.shape[0], dtype=np.float64)\n",
    "\n",
    "            sample_weight[:] = 1. / X.shape[0]\n",
    "\n",
    "        else:\n",
    "\n",
    "            sample_weight = check_array(sample_weight, ensure_2d=False)\n",
    "\n",
    "            # Normalize existing weights.\n",
    "\n",
    "            sample_weight = sample_weight/sample_weight.sum(dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "            # Check that the sample weights sum is positive.\n",
    "\n",
    "            if sample_weight.sum() <= 0:\n",
    "\n",
    "                raise ValueError(\n",
    "\n",
    "                    \"Attempting to fit with a non-positive \"\n",
    "\n",
    "                    \"weighted number of samples.\")\n",
    "\n",
    "\n",
    "\n",
    "        if minority_target is None:\n",
    "\n",
    "            # Determine the minority class label.\n",
    "\n",
    "            stats_c_ = Counter(y)\n",
    "\n",
    "            maj_c_ = max(stats_c_, key=stats_c_.get)\n",
    "\n",
    "            min_c_ = min(stats_c_, key=stats_c_.get)\n",
    "\n",
    "            self.minority_target = min_c_\n",
    "\n",
    "        else:\n",
    "\n",
    "            self.minority_target = minority_target\n",
    "\n",
    "\n",
    "\n",
    "        # Check parameters.\n",
    "\n",
    "        self._validate_estimator()\n",
    "\n",
    "\n",
    "\n",
    "        # Clear any previous fit results.\n",
    "\n",
    "        self.estimators_ = []\n",
    "\n",
    "        self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n",
    "\n",
    "        self.estimator_errors_ = np.ones(self.n_estimators, dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "\n",
    "\n",
    "\n",
    "        for iboost in range(self.n_estimators):\n",
    "\n",
    "            # SMOTE step.\n",
    "\n",
    "            X_min = X[np.where(y == self.minority_target)]\n",
    "\n",
    "            self.smote.fit(X_min)\n",
    "\n",
    "            X_syn = self.smote.sample(self.n_samples)\n",
    "\n",
    "            y_syn = np.full(X_syn.shape[0], fill_value=self.minority_target,\n",
    "\n",
    "                            dtype=np.int64)\n",
    "\n",
    "\n",
    "\n",
    "            # Normalize synthetic sample weights based on current training set.\n",
    "\n",
    "            sample_weight_syn = np.empty(X_syn.shape[0], dtype=np.float64)\n",
    "\n",
    "            sample_weight_syn[:] = 1. / X.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "            # Combine the original and synthetic samples.\n",
    "\n",
    "            X = np.vstack((X, X_syn))\n",
    "\n",
    "            y = np.append(y, y_syn)\n",
    "\n",
    "\n",
    "\n",
    "            # Combine the weights.\n",
    "\n",
    "            sample_weight = \\\n",
    "                np.append(sample_weight, sample_weight_syn).reshape(-1, 1)\n",
    "\n",
    "            sample_weight = \\\n",
    "                np.squeeze(normalize(sample_weight, axis=0, norm='l1'))\n",
    "\n",
    "\n",
    "\n",
    "            # X, y, sample_weight = shuffle(X, y, sample_weight,\n",
    "\n",
    "            #                              random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "            # Boosting step.\n",
    "\n",
    "            sample_weight, estimator_weight, estimator_error = self._boost(\n",
    "\n",
    "                iboost,\n",
    "\n",
    "                X, y,\n",
    "\n",
    "                sample_weight,\n",
    "\n",
    "                random_state)\n",
    "\n",
    "\n",
    "\n",
    "            # Early termination.\n",
    "\n",
    "            if sample_weight is None:\n",
    "\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "            self.estimator_weights_[iboost] = estimator_weight\n",
    "\n",
    "            self.estimator_errors_[iboost] = estimator_error\n",
    "\n",
    "\n",
    "\n",
    "            # Stop if error is zero.\n",
    "\n",
    "            if estimator_error == 0:\n",
    "\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "            sample_weight_sum = np.sum(sample_weight)\n",
    "\n",
    "\n",
    "\n",
    "            # Stop if the sum of sample weights has become non-positive.\n",
    "\n",
    "            if sample_weight_sum <= 0:\n",
    "\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "            if iboost < self.n_estimators - 1:\n",
    "\n",
    "                # Normalize.\n",
    "\n",
    "                sample_weight /= sample_weight_sum\n",
    "\n",
    "\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEBoost(algorithm='SAMME.R', base_estimator=None, k_neighbors=None,\n      learning_rate=1.0, n_estimators=50, n_samples=100, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "oversampler=SMOTEBoost()\n",
    "print(oversampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unorderable types: int() > str()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-770f285c3e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moversampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-472eb17f7621>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, minority_target)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'multiclass'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[1;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid axis kwarg specified for unique'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jason\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unorderable types: int() > str()"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "oversampler.fit(X_3,y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-903198846948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moversampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msmoteBoost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_smote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_s\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moversampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;31m#标准化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_smote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4d1b7a1d2031>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0msynthetic_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_numsamples_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                                 \u001b[0mdf_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_smote\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_smote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcl\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "#标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(X_smote)\n",
    "X_s=scaler.transform(X_smote)  #X是ndarray\n",
    "\n",
    "#可视化\n",
    "y_smote=pd.DataFrame(y_s,columns=['label'])\n",
    "print(y_smote.label.value_counts())\n",
    "\n",
    "classes_1=['Probing','Normal','U2R','DOS','R2L']\n",
    "plt.figure()\n",
    "plt.title(\"smoteBoost\")\n",
    "y_smote['label'].value_counts().plot(kind='bar',rot=45)\n",
    "# y_sc=[87832,87832,87832,87832,87832]\n",
    "# plt.pie(y_sc, colors=colors_1, labels=classes_1,autopct='%1.2f%%',pctdistance=0.7, shadow=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1,X_test_1,y_train_1,y_test_1=train_test_split(X_s,y_s,test_size=0.2,random_state=0)  #切分样本\n",
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(X_test_1)\n",
    "plt.figure()\n",
    "plt.title(\"smoteBoost\")\n",
    "classes=['Normal','Probing','DOS','U2R','R2L']\n",
    "colors=['blue','red','y','m','w']\n",
    "for index,label,color in zip(range(len(classes)),classes,colors):\n",
    "    plt.scatter(X_embedded[y_test_1==label,0],\n",
    "                X_embedded[y_test_1==label,1],\n",
    "                label=classes[index],\n",
    "                c=color)\n",
    "plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "#分类器\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "##建立模型\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "#验证测试样本\n",
    "clf_2.fit(X_train_1,y_train_1)\n",
    "preditions_smote=clf_2.predict(X_test_1)\n",
    "#学习曲线\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes,train_scores,test_scores=learning_curve(estimator=clf_2,\n",
    "                                X=X_train_1,y=y_train_1,\n",
    "                                train_sizes=np.linspace(0.05,1,10),\n",
    "                                 cv=10, n_jobs=1,random_state=0)\n",
    "train_mean_1=np.mean(train_scores,axis=1)\n",
    "test_mean_1=np.mean(test_scores,axis=1)\n",
    "train_std_1=np.std(train_scores,axis=1)\n",
    "test_std_1=np.std(train_scores,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}